---
layout: post
title:  "SpringCloudAlibaba高级实战"
date:   2021-07-07
categories: lagou
tags: lagou
---

* content
{:toc}


1. 第三阶段、分布式架构设计&微服务深入剖析
2. 第五模块、SpringCloud组件设计原理及实战（下）
3. 任务2、SpringCloudAlibaba高级实战
  




 
 
# 第七部分 第⼆代 Spring Cloud 核⼼组件（SCA）

第⼀代 Spring Cloud （主要是 SCN）很多组件已经进⼊停更维护模式。

Spring Cloud： Netflix， Spring官⽅， SCA（被Spring官⽅认可）

注意：市场上主要使⽤的还是SCN， SCA⼀套框架的集合

Alibaba 更进⼀步，搞出了Spring Cloud Alibaba（SCA）， SCA 是由⼀些阿⾥巴巴的开源组件和云产品组成的， 2018年， Spring Cloud Alibaba 正式⼊住了 Spring Cloud 官⽅孵化器。

* Nacos（服务注册中⼼、配置中⼼）
* Sentinel哨兵（服务的熔断、限流等）
* Dubbo RPC/LB
* Seata分布式事务解决⽅案

## 7.1 SCA Nacos 服务注册和配置中⼼
### 7.1.1 Nacos 介绍

Nacos （Dynamic Naming and Configuration Service）是阿⾥巴巴开源的⼀个针对微服务架构中服务发现、配置管理和服务管理平台。

Nacos就是注册中⼼+配置中⼼的组合（Nacos=Eureka+Config+Bus）

官⽹： https://nacos.io 下载地址： https://github.com/alibaba/Nacos

**Nacos功能特性**

* 服务发现与健康检查
* 动态配置管理
* 动态DNS服务
* 服务和元数据管理（管理平台的⻆度， nacos也有⼀个ui⻚⾯，可以看到注册的服务及其实例信息（元数据信息）等），动态的服务权重调整、动态服务优雅下线，都可以去做

### 7.1.2 Nacos 单例服务部署

下载解压安装包，执⾏命令启动（我们使⽤最近⽐较稳定的版本 nacos-server-1.2.0.tar.gz）
```
linux/mac： sh startup.sh -m standalone

windows： cmd startup.cmd
```

访问nacos管理界⾯： http://127.0.0.1:8848/nacos/#/login （默认端⼝8848，账号和密码nacos/nacos）

![访问nacos管理界⾯](/assets/lagou/第三阶段/05.第五模块/访问nacos管理界⾯.jpg)

### 7.1.3 Nacos 服务注册中⼼

**服务提供者注册到Nacos(改造简历微服务)**

在⽗pom中引⼊SCA依赖
```xml
<dependencyManagement>
    <dependencies>
        <!--SCA -->
        <dependency>
            <groupId>com.alibaba.cloud</groupId>
            <artifactId>spring-cloud-alibaba-dependencies</artifactId>
            <version>2.1.0.RELEASE</version>
            <type>pom</type>
            <scope>import</scope>
        </dependency>
    </dependencies>
    <!--SCA -->
</dependencyManagement>
```

在服务提供者⼯程中引⼊nacos客户端依赖（注释eureka客户端）
```xml
<dependency>
    <groupId>com.alibaba.cloud</groupId>
    <artifactId>spring-cloud-starter-alibaba-nacos-discovery</artifactId>
</dependency>
```

application.yml修改，添加nacos配置信息
```
server:
    port: 8082
spring:
    application:
        name: lagou-service-resume
    cloud:
        nacos:
            discovery:
            ################ 配置nacos server地址
                server-addr: 127.0.0.1:8848
    datasource:
        driver-class-name: com.mysql.jdbc.Driver
        url: jdbc:mysql://localhost:3306/lagou?
        useUnicode=true&characterEncoding=utf8
        username: root
        password: 123456
jpa:
    database: MySQL
    show-sql: true
    hibernate:
        naming:
            physical-strategy: org.hibernate.boot.model.naming.PhysicalNamingStrategyStandardImpl
management:
    endpoints:
        web:
            exposure:
                include: '*'
```

启动简历微服务，观察nacos控制台

![观察nacos控制台1](/assets/lagou/第三阶段/05.第五模块/观察nacos控制台1.jpg)

![观察nacos控制台2](/assets/lagou/第三阶段/05.第五模块/观察nacos控制台2.jpg)

保护阈值：可以设置为0-1之间的浮点数，它其实是⼀个⽐例值（当前服务健康实例数/当前服务总实例数）

场景：

⼀般流程下， nacos是服务注册中⼼，服务消费者要从nacos获取某⼀个服务的可⽤实例信息，对于服务实例有健康/不健康状态之分， nacos在返回给消费者实例信息的时候，会返回健康实例。这个时候在⼀些⾼并发、⼤流量场景下会存在⼀定的问题

如果服务A有100个实例， 98个实例都不健康了，只有2个实例是健康的，如果nacos只返回这两个健康实例的信息的话，那么后续消费者的请求将全部被分配到这两个实例，流量洪峰到来， 2个健康的实例也扛不住了，整个服务A 就扛不住，上游的微服务也会导致崩溃，产⽣雪崩效应。

保护阈值的意义在于

当服务A健康实例数/总实例数 < 保护阈值 的时候，说明健康实例真的不多了，这个时候保护阈值会被触发（状态true）

nacos将会把该服务所有的实例信息（健康的+不健康的）全部提供给消费者，消费者可能访问到不健康的实例，请求失败，但这样也⽐造成雪崩要好，牺牲了⼀些请求，保证了整个系统的⼀个可⽤。

注意：阿⾥内部在使⽤nacos的时候，也经常调整这个保护阈值参数。

**服务消费者从Nacos获取服务提供者(改造⾃动投递微服务)**

同服务提供者

测试
![观察nacos控制台3](/assets/lagou/第三阶段/05.第五模块/观察nacos控制台3.jpg)

![观察nacos控制台4](/assets/lagou/第三阶段/05.第五模块/观察nacos控制台4.jpg)

**负载均衡**

Nacos客户端引⼊的时候，会关联引⼊Ribbon的依赖包，我们使⽤OpenFiegn的时候也会引⼊Ribbon的依赖， Ribbon包括Hystrix都按原来⽅式进⾏配置即可

此处，我们将简历微服务，⼜启动了⼀个8083端⼝，注册到Nacos上，便于测试负载均衡，我们通过后台也可以看出

**Nacos 数据模型（领域模型）**
Namespace命名空间、 Group分组、集群这些都是为了进⾏归类管理，把服务和配置⽂件进⾏归类，归类之后就可以实现⼀定的效果，⽐如隔离

⽐如，对于服务来说，不同命名空间中的服务不能够互相访问调⽤

![领域模型](/assets/lagou/第三阶段/05.第五模块/领域模型.jpg)

* Namespace：命名空间，对不同的环境进⾏隔离，⽐如隔离开发环境、测试环境和⽣产环境
* Group：分组，将若⼲个服务或者若⼲个配置集归为⼀组，通常习惯⼀个系统归为⼀个组
* Service：某⼀个服务，⽐如简历微服务
* DataId：配置集或者可以认为是⼀个配置⽂件

**Namespace + Group + Service 如同 Maven 中的GAV坐标， GAV坐标是为了锁定Jar，⼆这⾥是为了锁定服务**

**Namespace + Group + DataId 如同 Maven 中的GAV坐标， GAV坐标是为了锁定Jar，⼆这⾥是为了锁定配置⽂件**

**最佳实践**

Nacos抽象出了Namespace、 Group、 Service、 DataId等概念，具体代表什么取决于怎么⽤（⾮常灵活），推荐⽤法如下

概念 | 描述
--|--
Namespace | 代表不同的环境，如开发dev、测试test、⽣产环境prod
Group | 代表某项⽬，⽐如拉勾云项⽬
Service | 某个项⽬中具体xxx服务
DataId | 某个项⽬中具体的xxx配置⽂件

Nacos服务的分级模型
![Nacos服务的分级模型](/assets/lagou/第三阶段/05.第五模块/Nacos服务的分级模型.jpg)

**Nacos Server 数据持久化**

Nacos 默认使⽤嵌⼊式数据库进⾏数据存储，它⽀持改为外部Mysql存储

新建数据库 nacos_config，数据库初始化脚本⽂件 ${nacoshome}/conf/nacos-mysql.sql

修改${nacoshome}/conf/application.properties，增加Mysql数据源配置
```
spring.datasource.platform=mysql
### Count of DB:
db.num=1
### Connect URL of DB:
db.url.0=jdbc:mysql://127.0.0.1:3306/nacos_config?characterEncoding=utf8&connectTimeout=1000&socketTimeout=3000&autoReconnect=true
db.user=root
db.password=123456
```

**Nacos Server 集群**

* 安装3个或3个以上的Nacos

复制解压后的nacos⽂件夹，分别命名为nacos-01、 nacos-02、 nacos-03

修改配置⽂件

同⼀台机器模拟，将上述三个⽂件夹中application.properties中的server.port分别改为8848、 8849、 8850

同时给当前实例节点绑定ip，因为服务器可能绑定多个ip
```
nacos.inetutils.ip-address=127.0.0.1
```
复制⼀份conf/cluster.conf.example⽂件，命名为cluster.conf
在配置⽂件中设置集群中每⼀个节点的信息

```
# 集群节点配置
127.0.0.1:8848
127.0.0.1:8849
127.0.0.1:8850 
```

分别启动每⼀个实例（可以批处理脚本完成）

```
sh startup.sh -m cluster
```

### 7.1.4 Nacos 配置中⼼
之前： Spring Cloud Config + Bus

>1) Github 上添加配置⽂件
>2）创建Config Server 配置中⼼—>从Github上去下载配置信息
>3）具体的微服务(最终使⽤配置信息的)中配置Config Client—> ConfigServer获取配置信息

有Nacos之后，分布式配置就简单很多

Github不需要了（配置信息直接配置在Nacos server中）， Bus也不需要了(依然可以完成动态刷新)

接下来  
1、去Nacos server中添加配置信息  
2、改造具体的微服务，使其成为Nacos Config Client，能够从Nacos Server中获取到配置信息

**Nacos server 添加配置集**

![添加配置集](/assets/lagou/第三阶段/05.第五模块/添加配置集.jpg)

Nacos 服务端已经搭建完毕，那么我们可以在我们的微服务中开启 Nacos 配置管理

1）添加依赖
```xml
<dependency>
    <groupId>com.alibaba.cloud</groupId>
    <artifactId>spring-cloud-starter-alibaba-nacos-config</artifactId>
</dependency>
```

2）微服务中如何锁定 Nacos Server 中的配置⽂件（dataId）

通过 Namespace + Group + dataId 来锁定配置⽂件， Namespace不指定就默认public， Group不指定就默认 DEFAULT_GROUP

**dataId 的完整格式如下**

```
${prefix}-${spring.profile.active}.${file-extension}
```

* prefix 默认为 spring.application.name 的值，也可以通过配置项 spring.cloud.nacos.config.prefix 来配置。
* spring.profile.active 即为当前环境对应的 profile。 注意：当 spring.profile.active 为空时，对应的连接符 - 也将不存在， dataId 的拼接格式变成 ${prefix}.${fileextension}
* file-exetension 为配置内容的数据格式，可以通过配置项 spring.cloud.nacos.config.file-extension 来配置。⽬前只⽀持 properties 和 yaml 类型。
```
cloud:
    nacos:
        discovery:
        # 集群中各节点信息都配置在这⾥（域名-VIP-绑定映射到各个实例的地址信息）
            server-addr: 127.0.0.1:8848
        config:
            server-addr: 127.0.0.1:8848
            namespace: f965f7e4-7294-40cf-825c-ef363c269d37
            group: DEFAULT_GROUP
            file-extension: yaml
```

3）通过 Spring Cloud 原⽣注解 @RefreshScope 实现配置⾃动更新
```java
package com.lagou.edu.controller;
import org.springframework.beans.factory.annotation.Value;
import org.springframework.cloud.context.config.annotation.RefreshScope;
import org.springframework.web.bind.annotation.GetMapping;
import org.springframework.web.bind.annotation.RequestMapping;
import org.springframework.web.bind.annotation.RestController;
/**
 * 该类⽤于模拟，我们要使⽤共享的那些配置信息做⼀些事情
 */
@RestController
@RequestMapping("/config")
@RefreshScope
public class ConfigController {
    // 和取本地配置信息⼀样
    @Value("${lagou.message}")
    private String lagouMessage;
    @Value("${mysql.url}")
    private String mysqlUrl;
    // 内存级别的配置信息
    // 数据库， redis配置信息
    @GetMapping("/viewconfig")
    public String viewconfig() {
        return "lagouMessage==>" + lagouMessage + " mysqlUrl=>" + mysqlUrl;
    }
}
```

思考：⼀个微服务希望从配置中⼼Nacos server中获取多个dataId的配置信息，可以的，扩展多个dataId
```
# nacos配置
cloud:
    nacos:
        discovery:
            # 集群中各节点信息都配置在这⾥（域名-VIP-绑定映射到各个实例的地址信息）
            server-addr: 127.0.0.1:8848,127.0.0.1:8849,127.0.0.1:8850
        # nacos config 配置
        config:
            server-addr: 127.0.0.1:8848,127.0.0.1:8849,127.0.0.1:8850
            # 锁定server端的配置⽂件（读取它的配置项）
            namespace: 07137f0a-bf66-424b-b910-20ece612395a # 命名空间id
            group: DEFAULT_GROUP # 默认分组就是DEFAULT_GROUP，如果使⽤默认分组可以不配置
            file-extension: yaml #默认properties
            # 根据规则拼接出来的dataId效果： lagou-service-resume.yaml
            ext-config[0]:
                data-id: abc.yaml
                group: DEFAULT_GROUP
                refresh: true #开启扩展dataId的动态刷新
            ext-config[1]:
                data-id: def.yaml
                group: DEFAULT_GROUP
                refresh: true #开启扩展dataId的动态刷新
```

优先级：根据规则⽣成的dataId > 扩展的dataId（对于扩展的dataId， [n] n越⼤优先级越⾼）


## 7.2 SCA Sentinel 分布式系统的流量防卫兵
### 7.2.1 Sentinel 介绍

Sentinel是⼀个⾯向云原⽣微服务的流量控制、熔断降级组件。

替代Hystrix，针对问题：服务雪崩、服务降级、服务熔断、服务限流

Hystrix：  
服务消费者（⾃动投递微服务） —>调⽤服务提供者（简历微服务）  

在调⽤⽅引⼊Hystrix—> 单独搞了⼀个Dashboard项⽬—>Turbine

1）⾃⼰搭建监控平台 dashboard

2）没有提供UI界⾯进⾏服务熔断、服务降级等配置（⽽是写代码，⼊侵了我们源程序环境）

Sentinel：

1）独⽴可部署Dashboard/控制台组件

2）减少代码开发，通过UI界⾯配置即可完成细粒度控制（⾃动投递微服务）

![Sentinel](/assets/lagou/第三阶段/05.第五模块/Sentinel.jpg)

Sentinel 分为两个部分:

核⼼库：（Java 客户端）不依赖任何框架/库，能够运⾏于所有 Java 运⾏时环境，同时对 Dubbo / Spring Cloud 等框架也有较好的⽀持

控制台：（Dashboard）基于 Spring Boot 开发，打包后可以直接运⾏，不需要额外的 Tomcat 等应⽤容器。

Sentinel 具有以下特征:
* **丰富的应⽤场景**： Sentinel 承接了阿⾥巴巴近 10 年的双⼗⼀⼤促流量的核⼼场景，例如秒杀（即突发流量控制在系统容量可以承受的范围）、消息削峰填⾕、集群流量控制、实时熔断下游不可⽤应⽤等。
* **完备的实时监控**： Sentinel 同时提供实时的监控功能。您可以在控制台中看到接⼊应⽤的单台机器秒级数据，甚⾄ 500 台以下规模的集群的汇总运⾏情况。
* **⼴泛的开源⽣态**： Sentinel 提供开箱即⽤的与其它开源框架/库的整合模块，例如与 Spring Cloud、 Dubbo的整合。您只需要引⼊相应的依赖并进⾏简单的配置即可快速地接⼊ Sentinel。
* **完善的 SPI 扩展点**： Sentinel 提供简单易⽤、完善的 SPI 扩展接⼝。您可以通过实现扩展接⼝来快速地定制逻辑。例如定制规则管理、适配动态数据源等

Sentinel 的主要特性：

![主要特性](/assets/lagou/第三阶段/05.第五模块/主要特性.jpg)

### 7.2.2 Sentinel 部署

下载地址： https://github.com/alibaba/Sentinel/releases 我们使⽤v1.7.1

启动： java -jar sentinel-dashboard-1.7.1.jar &

⽤户名/密码： sentinel/sentinel

### 7.2.3 服务改造

在我们已有的业务场景中， “⾃动投递微服务”调⽤了“简历微服务”，我们在⾃动投递微服务进⾏的熔断降级等控制，那么接下来我们改造⾃动投递微服务，引⼊Sentinel核⼼包。

为了不污染之前的代码，复制⼀个⾃动投递微服务 lagou-service-autodeliver-8098-sentinel

pom.xml引⼊依赖

```xml
<!--sentinel 核⼼环境 依赖-->
<dependency>
    <groupId>com.alibaba.cloud</groupId>
    <artifactId>spring-cloud-starter-alibaba-sentinel</artifactId>
</dependency>
```

application.yml修改（配置sentinel dashboard，暴露断点依然要有，删除原有hystrix配置，删除原有OpenFeign的降级配置）
```
server:
    port: 8098
spring:
    application:
        name: lagou-service-autodeliver
    cloud:
        nacos:
            discovery:
                server-addr: 127.0.0.1:8848
        sentinel:
            transport:
                dashboard: 127.0.0.1:8080 # sentinel dashboard/console 地址
                port: 8719 # sentinel会在该端⼝启动http server，那么这样的话，控制台定义的⼀些限流等规则才能发送传递过来，
                            #如果8719端⼝被占⽤，那么会依次+1
management:
    endpoints:
        web:
            exposure:
                include: "*"
    # 暴露健康接⼝的细节
    endpoint:
        health:
            show-details: always
#针对的被调⽤⽅微服务名称,不加就是全局⽣效
lagou-service-resume:
    ribbon:
        #请求连接超时时间
        ConnectTimeout: 2000
        #请求处理超时时间
        ##########################################Feign超时时⻓设置
        ReadTimeout: 3000
        #对所有操作都进⾏重试
        OkToRetryOnAllOperations: true
        ####根据如上配置，当访问到故障请求的时候，它会再尝试访问⼀次当前实例（次数由
        MaxAutoRetries配置），
        ####如果不⾏，就换⼀个实例进⾏访问，如果还不⾏，再换⼀次实例访问（更换次数由
        MaxAutoRetriesNextServer配置）
        ####如果依然不⾏，返回失败信息。
        MaxAutoRetries: 0 #对当前选中实例重试次数，不包括第⼀次调⽤
        MaxAutoRetriesNextServer: 0 #切换实例的重试次数
        NFLoadBalancerRuleClassName: com.netflix.loadbalancer.RoundRobinRule #负载策略调整
logging:
    level:
        # Feign⽇志只会对⽇志级别为debug的做出响应
        com.lagou.edu.controller.service.ResumeServiceFeignClient: debug
```

上述配置之后，启动⾃动投递微服务，使⽤ Sentinel 监控⾃动投递微服务,此时我们发现控制台没有任何变化，因为懒加载，我们只需要发起⼀次请求触发即可

![sentinel监控](/assets/lagou/第三阶段/05.第五模块/sentinel监控.jpg)

### 7.2.4 Sentinel 关键概念

概 念 名 称 | 概念描述
--|--
资 源 | 它可以是 Java 应⽤程序中的任何内容，例如，由应⽤程序提供的服务，或由应⽤程序调⽤的其它应⽤提供的服务，甚⾄可以是⼀段代码。 我们请求的API接⼝就是资源
规 则 | 围绕资源的实时状态设定的规则，可以包括流量控制规则、熔断降级规则以及系统保护规则。所有规则可以动态实时调整

### 7.2.5 Sentinel 流量规则模块

系统并发能⼒有限，⽐如系统A的QPS⽀持1个，如果太多请求过来，那么A就应该进⾏流量控制了，⽐如其他请求直接拒绝

![流量规则模块](/assets/lagou/第三阶段/05.第五模块/流量规则模块.jpg)

**资源名：默认请求路径**

* 针对来源： Sentinel可以针对调⽤者进⾏限流，填写微服务名称，默认default（不区分来源）

**阈值类型/单机阈值**

* QPS：（每秒钟请求数量）当调⽤该资源的QPS达到阈值时进⾏限流

* 线程数：当调⽤该资源的线程数达到阈值的时候进⾏限流（线程处理请求的时候，如果说业务逻辑执⾏时间很⻓，流量洪峰来临时，会耗费很多线程资源，这些线程资源会堆积，最终可能造成服务不可⽤，进⼀步上游服务不可⽤，最终可能服务雪崩）

* 是否集群：是否集群限流

**流控模式：**

>直接：资源调⽤达到限流条件时，直接限流  
>关联：关联的资源调⽤达到阈值时候限流⾃⼰  
>链路：只记录指定链路上的流量  

**流控效果：**

快速失败：直接失败，抛出异常

Warm Up：根据冷加载因⼦（默认3）的值，从阈值/冷加载因⼦，经过预热时⻓，才达到设置的QPS阈值

排队等待：匀速排队，让请求匀速通过，阈值类型必须设置为QPS，否则⽆效

**流控模式之关联限流**:关联的资源调⽤达到阈值时候限流⾃⼰，⽐如⽤户注册接⼝，需要调⽤身份证校验接⼝（往往身份证校验接⼝），如果身份证校验接⼝请求达到阈值，使⽤关联，可以对⽤户注册接⼝进⾏限流

![流控模式之关联限流](/assets/lagou/第三阶段/05.第五模块/流控模式之关联限流.jpg)

```java
package com.lagou.edu.controller;
import com.lagou.edu.controller.service.ResumeServiceFeignClient;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.web.bind.annotation.GetMapping;
import org.springframework.web.bind.annotation.PathVariable;
import org.springframework.web.bind.annotation.RequestMapping;
import org.springframework.web.bind.annotation.RestController;
@RestController
@RequestMapping("/user")
public class UserController {
    /**
     * ⽤户注册接⼝
     * @return
     */
    @GetMapping("/register")
    public String register() {
        System.out.println("Register success!");
        return "Register success!";
    }
    /**
     * 验证注册身份证接⼝（需要调⽤公安户籍资源）
     * @return
     */
    @GetMapping("/validateID")
        public String findResumeOpenState() {
        System.out.println("validateID");
        return "ValidateID success!";
    }
}
```

模拟密集式请求/user/validateID验证接⼝，我们会发现/user/register接⼝也被限流了

**流控模式之链路限流**

链路指的是请求链路（调⽤链）

链路模式下会控制该资源所在的调⽤链路⼊⼝的流量。需要在规则中配置⼊⼝资源，即该调⽤链路⼊⼝的上下⽂名称。

![流控模式之链路限流](/assets/lagou/第三阶段/05.第五模块/流控模式之链路限流.jpg)

上图中来⾃⼊⼝ Entrance1 和 Entrance2 的请求都调⽤到了资源 NodeA ， Sentinel 允许只根据某个调⽤⼊⼝的统计信息对资源限流。⽐如链路模式下设置⼊⼝资源为 Entrance1 来表示只有从⼊⼝Entrance1 的调⽤才会记录到 NodeA 的限流统计当中，⽽不关⼼经 Entrance2 到来的调⽤。

![流控模式之链路限流2](/assets/lagou/第三阶段/05.第五模块/流控模式之链路限流2.jpg)

**流控效果之Warm up**

当系统⻓期处于空闲的情况下，当流量突然增加时，直接把系统拉升到⾼⽔位可能瞬间把系统压垮，⽐如电商⽹站的秒杀模块。

通过 Warm Up 模式（预热模式），让通过的流量缓慢增加，经过设置的预热时间以后，到达系统处理请求速率的设定值。

Warm Up 模式默认会从设置的 QPS 阈值的 1/3 开始慢慢往上增加⾄ QPS 设置值。

![流控效果之Warm](/assets/lagou/第三阶段/05.第五模块/流控效果之Warm.jpg)

**流控效果之排队等待**

排队等待模式下会严格控制请求通过的间隔时间，即请求会匀速通过，允许部分请求排队等待，通常⽤于消息队列削峰填⾕等场景。需设置具体的超时时间，当计算的等待时间超过超时时间时请求就会被拒绝。

很多流量过来了，并不是直接拒绝请求，⽽是请求进⾏排队，⼀个⼀个匀速通过（处理），请求能等就等着被处理，不能等（等待时间>超时时间）就会被拒绝

例如， QPS 配置为 5，则代表请求每 200 ms 才能通过⼀个，多出的请求将排队等待通过。超时时间代表最⼤排队时间，超出最⼤排队时间的请求将会直接被拒绝。排队等待模式下， QPS 设置值不要超过1000（请求间隔 1 ms）。

### 7.2.6 Sentinel 降级规则模块

流控是对外部来的⼤流量进⾏控制，熔断降级的视⻆是对内部问题进⾏处理。

Sentinel 降级会在调⽤链路中某个资源出现不稳定状态时（例如调⽤超时或异常⽐例升⾼），对这个资源的调⽤进⾏限制，让请求快速失败，避免影响到其它的资源⽽导致级联错误。当资源被降级后，在接下来的降级时间窗⼝之内，对该资源的调⽤都⾃动熔断.

**=======>>>> 这⾥的降级其实是Hystrix中的熔断**

还记得当时Hystrix的⼯作流程么

![Hystrix](/assets/lagou/第三阶段/05.第五模块/Hystrix.jpg)

**策略**

Sentinel不会像Hystrix那样放过⼀个请求尝试⾃我修复，就是明明确确按照时间窗⼝来，熔断触发后，时间窗⼝内拒绝请求，时间窗⼝后就恢复。

**1.RT（平均响应时间 ）**

当 1s 内持续进⼊ >=5 个请求，平均响应时间超过阈值（以 ms 为单位），那么在接下的时间窗⼝（以 s 为单位）之内，对这个⽅法的调⽤都会⾃动地熔断（抛出 DegradeException）。注意Sentinel 默认统计的 RT 上限是 4900 ms，超出此阈值的都会算作 4900 ms，若需要变更此上限可以通过启动配置项 -Dcsp.sentinel.statistic.max.rt=xxx 来配置。

![RT](/assets/lagou/第三阶段/05.第五模块/RT.jpg)

**2.异常⽐例**

当资源的每秒请求量 >= 5，并且每秒异常总数占通过量的⽐值超过阈值之后，资源进⼊降级状态，即在接下的时间窗⼝（以 s 为单位）之内，对这个⽅法的调⽤都会⾃动地返回。异常⽐率的阈值范围是 [0.0, 1.0] ，代表 0% - 100%。

![异常⽐例](/assets/lagou/第三阶段/05.第五模块/异常⽐例.jpg)

**3.异常数**

当资源近 1 分钟的异常数⽬超过阈值之后会进⾏熔断。注意由于统计时间窗⼝是分钟级别的，若timeWindow ⼩于 60s，则结束熔断状态后仍可能再进⼊熔断状态。

时间窗⼝ >= 60s

![异常数](/assets/lagou/第三阶段/05.第五模块/异常数.jpg)

### 7.2.8 Sentinel ⾃定义兜底逻辑

@SentinelResource注解类似于Hystrix中的@HystrixCommand注解

@SentinelResource注解中有两个属性需要我们进⾏区分， blockHandler属性⽤来指定不满⾜Sentinel规则的降级兜底⽅法， fallback属性⽤于指定Java运⾏时异常兜底⽅法

在API接⼝资源处配置
```java
/**
 * @SentinelResource
    value：定义资源名
    blockHandlerClass：指定Sentinel规则异常兜底逻辑所在class类
    blockHandler：指定Sentinel规则异常兜底逻辑具体哪个⽅法
    fallbackClass：指定Java运⾏时异常兜底逻辑所在class类
    fallback：指定Java运⾏时异常兜底逻辑具体哪个⽅法
*/
@GetMapping("/checkState/{userId}")
@SentinelResource(value = "findResumeOpenState",blockHandlerClass = SentinelFallbackClass.class,blockHandler = "handleException",fallback ="handleError",fallbackClass = SentinelFallbackClass.class)
public Integer findResumeOpenState(@PathVariable Long userId) {
// 模拟降级：
/*try {
    Thread.sleep(1000);
} catch (InterruptedException e) {
    e.printStackTrace();
}*/
// 模拟降级：异常⽐例
    int i = 1/0;
    Integer defaultResumeState =
    resumeServiceFeignClient.findDefaultResumeState(userId);
    return defaultResumeState;
}
```

⾃定义兜底逻辑类

注意：兜底类中的⽅法为static静态⽅法

```java
package com.lagou.edu.config;
import com.alibaba.csp.sentinel.slots.block.BlockException;
public class SentinelHandlersClass {
    // 整体要求和当时Hystrix⼀样，这⾥还需要在形参最后添加BlockException参数，⽤于接收异常
    // 注意：⽅法是静态的
    public static Integer handleException(Long userId, BlockException blockException) {
        return -100;
    }
    public static Integer handleError(Long userId) {
        return -500;
    }
}
```

### 7.2.9 基于 Nacos 实现 Sentinel 规则持久化

⽬前， Sentinel Dashboard中添加的规则数据存储在内存，微服务停掉规则数据就消失，在⽣产环境下不合适。我们可以将Sentinel规则数据持久化到Nacos配置中⼼，让微服务从Nacos获取规则数据。

![SentinelNacos](/assets/lagou/第三阶段/05.第五模块/SentinelNacos.jpg)

⾃动投递微服务的pom.xml中添加依赖
```xml
<!-- Sentinel⽀持采⽤ Nacos 作为规则配置数据源，引⼊该适配依赖 -->
<dependency>
    <groupId>com.alibaba.csp</groupId>
    <artifactId>sentinel-datasource-nacos</artifactId>
</dependency>
```

⾃动投递微服务的application.yml中配置Nacos数据源
```
spring:
    application:
        name: lagou-service-autodeliver
    cloud:
        nacos:
            discovery:
                server-addr: 127.0.0.1:8848,127.0.0.1:8849,127.0.0.1:8850
        sentinel:
            transport:
                dashboard: 127.0.0.1:8080 # sentinel dashboard/console 地址
                port: 8719 # sentinel会在该端⼝启动http server，那么这样的话，控制台定义的⼀些限流等规则才能发送传递过来，
                #如果8719端⼝被占⽤，那么会依次+1
                # Sentinel Nacos数据源配置， Nacos中的规则会⾃动同步到sentinel控制台的流控规则中
            datasource:
                # 此处的flow为⾃定义数据源名
                flow: # 流控规则
                    nacos:
                        server-addr: ${spring.cloud.nacos.discovery.server-addr}
                        data-id: ${spring.application.name}-flow-rules
                        groupId: DEFAULT_GROUP
                        data-type: json
                        rule-type: flow # 类型来⾃ RuleType类
                degrade:
                    nacos:
                        server-addr: ${spring.cloud.nacos.discovery.server-addr}
                        data-id: ${spring.application.name}-degrade-rules
                        groupId: DEFAULT_GROUP
                        data-type: json
                        rule-type: degrade # 类型来⾃ RuleType类
```

Nacos Server中添加对应规则配置集（public命名空间—>DEFAULT_GROUP中添加）流控规则配置集 lagou-service-autodeliver-flow-rules
```json
[
    {
        "resource":"findResumeOpenState",
        "limitApp":"default",
        "grade":1,
        "count":1,
        "strategy":0,
        "controlBehavior":0,
        "clusterMode":false
    }
]
```

**所有属性来⾃源码FlowRule类**

* resource：资源名称
* limitApp：来源应⽤
* grade：阈值类型 0 线程数 1 QPS
* count：单机阈值
* strategy：流控模式， 0 直接 1 关联 2 链路
* controlBehavior：流控效果， 0 快速失败 1 Warm Up 2 排队等待
* clusterMode： true/false 是否集群

降级规则配置集 lagou-service-autodeliver-degrade-rules
```
[
    {
        "resource":"findResumeOpenState",
        "grade":2,
        "count":1,
        "timeWindow":5
    }
]
```

**所有属性来⾃源码DegradeRule类**

* resource：资源名称
* grade：降级策略 0 RT 1 异常⽐例 2 异常数
* count：阈值
* timeWindow：时间窗

**Rule 源码体系结构**

![Rule](/assets/lagou/第三阶段/05.第五模块/Rule.jpg)

注意

>1）⼀个资源可以同时有多个限流规则和降级规则，所以配置集中是⼀个json数组  
>2） Sentinel控制台中修改规则，仅是内存中⽣效，不会修改Nacos中的配置值，重启后恢复原来的值； Nacos控制台中修改规则，不仅内存中⽣效， Nacos中持久化规则也⽣效，重启后规则依然保持

## 7.3 SCA ⼩结

1）因为内容重叠， SCA 中的分布式事务解决⽅案 Seata 会在紧接着的Mysql课程中讲解

2） SCA实际上发展了三条线

- 第⼀条线：开源出来⼀些组件
- 第⼆条线：阿⾥内部维护了⼀个分⽀，⾃⼰业务线使⽤
- 第三条线：阿⾥云平台部署⼀套，付费使⽤

从战略上来说， SCA更是为了贴合阿⾥云。

⽬前来看，开源出来的这些组件，推⼴及普及率不⾼，社区活跃度不⾼，稳定性和体验度上仍需进⼀步提升，根据实际使⽤来看Sentinel的稳定性和体验度要好于Nacos。







